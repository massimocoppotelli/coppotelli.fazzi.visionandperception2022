{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Students:\n",
        "\n",
        "Enrico Fazzi - 2003876\n",
        "\n",
        "Massimo Coppotelli - 1705325"
      ],
      "metadata": {
        "id": "U3GOVePsLF4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vision project: Diabethic Retinopathy Detection and Classification\n"
      ],
      "metadata": {
        "id": "3EoopSr6Kifl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj6Fkcm5RgQL"
      },
      "source": [
        "###Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFhUe52nRg88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "f8c3e0b2-ed48-430f-aaf8-827e8da6ed32"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1505f8ffe7e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_preprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;31m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_add_docstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_einsum\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopt_einsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_lowrank\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvd_lowrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca_lowrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m from .overrides import (\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from .parameter import (\n\u001b[1;32m      3\u001b[0m     \u001b[0mParameter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mUninitializedParameter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mUninitializedParameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mUninitializedBuffer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mUninitializedBuffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIdentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBilinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyLinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mConvTranspose1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConvTranspose2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConvTranspose3d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mLazyConv1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyConv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyConv3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyConvTranspose1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyConvTranspose2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyConvTranspose3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUninitializedParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mDType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mboolean_dispatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_overload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBroadcastingList1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBroadcastingList2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBroadcastingList3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m from ..overrides import (\n\u001b[1;32m     20\u001b[0m     \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Explicitly ask to import `torch.distributed.__init__` first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Otherwise, \"AttributeError: module 'torch' has no attribute 'distributed'\" is raised.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mangling\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpackage_mangling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFuture\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mCFuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/distributed/rpc/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m     )  # noqa: F401\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_registry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/distributed/rpc/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m from torch._C._distributed_rpc import (\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd \n",
        "import os \n",
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "from keras_preprocessing import image\n",
        "import random\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv2\n",
        "from skimage import io\n",
        "\n",
        "\n",
        "from torch.utils import data  \n",
        "import torch \n",
        "from torch import nn \n",
        "from torch import optim \n",
        "import torchvision  \n",
        "import torch.nn.functional as F \n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.utils import save_image\n",
        "import torchvision.models as models \n",
        "from torch.utils.data.sampler import SubsetRandomSampler \n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "from torch.optim import lr_scheduler \n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import time\n",
        "from joblib import Parallel, delayed\n",
        "import joblib\n",
        "\n",
        "from PIL import Image "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKb73MHUWVLC"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ajfjrt8QbLm",
        "outputId": "51533fdd-00a6-4829-fe13-2cca8f2f52ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# importing data from drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_csv = pd.read_csv('/content/drive/My Drive/VP/train.csv')\n",
        "\n",
        "\n",
        "base_dir = \"/content/drive/My Drive/VP\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAv9hBorDNtn"
      },
      "outputs": [],
      "source": [
        "# initialization of the dataset we will work on\n",
        "\n",
        "class OurDataset (Dataset): \n",
        "  def __init__(self,csv_values,root_dir = '/content/drive/My Drive', transform= None):\n",
        "    super().__init__()\n",
        "    self.values =csv_values.values\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.values)\n",
        "\n",
        "  def  __getitem__(self,index):\n",
        "    img_name,label = self.values[index]\n",
        "    img_path = os.path.join (self.root_dir, img_name+'.png')\n",
        "    image = cv2.imread(img_path)\n",
        "\n",
        "    if self.transform is not None:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return image,label "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhoxpqd8c5Nm"
      },
      "source": [
        "### Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac_H8fshQShq"
      },
      "source": [
        "Definition of training set and image transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDF9QW7EqaKQ"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(), # all transformations work on this format\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.25),\n",
        "    transforms.ColorJitter(brightness=0.25, contrast=0.1),\n",
        "    #transforms.RandomRotation(degrees=20),\n",
        "    #transforms.RandomVerticalFlip(p=0.1),\n",
        "    transforms.RandomGrayscale(p = 0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)) # (val - mean) / std\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl-GYMqrFMpt"
      },
      "outputs": [],
      "source": [
        "train_dataset = OurDataset (csv_values = train_csv, root_dir = '/content/drive/My Drive/VP/train_images/', transform = train_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghh-XM_XrZbm"
      },
      "source": [
        "### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-ejMVPf3l0c"
      },
      "outputs": [],
      "source": [
        "#splitting the training set in this way: 0.6 train, 0.2 valid, 0.2 test\n",
        "\n",
        "valid_size = 0.2 #valid size is equal to test size\n",
        "num_train = len(train_dataset) \n",
        "indices = list(range(num_train)) #creates a list within the range of the number of training\n",
        "np.random.shuffle(indices) # it reorders randomly the indices in the list\n",
        "split1 = int(np.floor(valid_size * num_train))    # split is an integer values, floor(x) è la parte intera di x\n",
        "split2 = 2*split1\n",
        "train_idx, valid_idx, test_idx = indices[split2:], indices[split1:split2], indices[:split1]   # divides the two sets in training and validation according to split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the three sets we will use to train and test our models"
      ],
      "metadata": {
        "id": "sBMkXA7pOlrh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlc5iSVnbaOr"
      },
      "outputs": [],
      "source": [
        "batch_size=64\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMwx-Bo3bBOR"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, sampler=train_sampler, shuffle = False)\n",
        "valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, sampler=valid_sampler)\n",
        "test_loader  = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, sampler=test_sampler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VGUUwZ_XpoP"
      },
      "source": [
        "## Importing architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzL9lEIiXsK3",
        "outputId": "1b154771-e727-4b34-e730-1aa6a03d44ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available! Training on GPU ...\n"
          ]
        }
      ],
      "source": [
        "# working on GPU\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "  print('CUDA is not available. Training on CPU ...')\n",
        "else:\n",
        "  print('CUDA is available! Training on GPU ...')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p78922aP1e_7"
      },
      "source": [
        "#### Resnet 152\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxgX01vQYBy3"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet152(pretrained=True) # we are using a resnet152\n",
        "num_ftrs = model.fc.in_features # with preset features\n",
        "out_ftrs = 5 # and 5 output features corresponding to the 5 classes\n",
        "\n",
        "# we will use a sequential fully connected network defined here\n",
        "\n",
        "model.fc = nn.Sequential(nn.Linear(num_ftrs, 512),nn.ReLU(),nn.Linear(512,out_ftrs),nn.LogSoftmax(dim=1)) #linear classifier\n",
        "\n",
        "#model = joblib.load('/content/drive/MyDrive/VP/model.pkl') ###uncomment when already working with a fine-tuned ResNet\n",
        "\n",
        "criterion = nn.NLLLoss() # negative log likelyhood loss function, useful for class. problems\n",
        "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.0001,weight_decay=0.05)  # Adam optimizer stochastic gradient descent\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) # adaptive learning rate\n",
        "model.to(device);\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf7t_BAl-aYW"
      },
      "outputs": [],
      "source": [
        "#save the model to re-use it\n",
        "\n",
        "model_save_name = \"classifier.pt\"\n",
        "path = F\"/content/drive/My Drive/VP/{model_save_name}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EkgYnTfuCsq",
        "outputId": "5c0b27ef-a667-43e7-c917-d413901902be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1is frozen\n",
            "bn1is frozen\n",
            "reluis frozen\n",
            "maxpoolis frozen\n",
            "layer1is frozen\n",
            "layer2is unfrozen\n",
            "layer3is unfrozen\n",
            "layer4is unfrozen\n",
            "avgpoolis frozen\n",
            "fcis unfrozen\n"
          ]
        }
      ],
      "source": [
        "# to unfreeze more layers --- Fine-tuning\n",
        "\n",
        "for name,child in model.named_children():\n",
        "  if name in ['layer2','layer3','layer4','fc']:\n",
        "    print(name + 'is unfrozen')\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = True\n",
        "  else:\n",
        "    print(name + 'is frozen')\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.0001, weight_decay=0.05)  # Adam optimizer stochastic gradient descent\n",
        "lambda1 = lambda epoch: 0.65 ** epoch\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZLhWfQQ2mHI"
      },
      "source": [
        "#### GoogleNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFWSb_6BWRCO"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.googlenet(pretrained=True) # we are using a GoogleNet\n",
        "dropout= 0.1 #set dropout\n",
        "num_ftrs = model.fc.in_features # with preset features\n",
        "out_ftrs = 5 # and 5 output features corresponding to the 5 classes\n",
        "\n",
        "# we will use a sequential fully connected network defined here\n",
        "\n",
        "model.fc = nn.Sequential(nn.Linear(num_ftrs, 1024),nn.ReLU(),nn.Linear(1024, out_ftrs),nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss() # negative log likelyhood loss function, useful for class. problems\n",
        "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.01, weight_decay=0.01)  # Adam optimizer stochastic gradient descent\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) # adaptive learning rate\n",
        "model.to(device);\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model to re-use it\n",
        "\n",
        "model_save_name = \"classifier.pt\"\n",
        "path = F\"/content/drive/My Drive/VP/{model_save_name}\""
      ],
      "metadata": {
        "id": "mFePWb5AP1X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to unfreeze more layers --- Fine-tuning the model\n",
        "\n",
        "for name,child in model.named_children():\n",
        "  if name in ['inception5a','inception5b','avgpool','dropout','fc']:\n",
        "    print(name + 'is unfrozen')\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = True\n",
        "  else:\n",
        "    print(name + 'is frozen')\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.01)  # Adam optimizer stochastic gradient descent\n",
        "lambda1 = lambda epoch: 0.65 ** epoch\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)"
      ],
      "metadata": {
        "id": "yRuoUfebP3mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEu7pUryEFmF"
      },
      "outputs": [],
      "source": [
        "#printing the model\n",
        "model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbs9kAFa2tOS"
      },
      "source": [
        "#### EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkIxolTol2cZ",
        "outputId": "e01bf578-39ca-4dd7-c728-cc9109f7221b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from efficientnet_pytorch) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->efficientnet_pytorch) (4.4.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=87c00ee254ab163966d6f37d9a1dd98e6ffc5ada404c690674ee2a604d236350\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/b9/90/25a0195cf95fb5533db96f1c77ea3f296b7cc86ae8ae48e3dc\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ],
      "source": [
        "# installing the architecture \n",
        "\n",
        "!pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "FJ1-rkR00kOd",
        "outputId": "cff91873-4862-47ee-bfcb-7d69b48564f2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c5cabacba048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mefficientnet_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEfficientNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEfficientNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'efficientnet-b7'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_ftrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'out_ftrs' is not defined"
          ]
        }
      ],
      "source": [
        "# importing EfficientNet-b7\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=out_ftrs)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "out_ftrs = 5 #5 output features corresponding to the 5 classes\n",
        "\n",
        "\n",
        "dropout= 0.01\n",
        "num_ftrs =  model._fc.in_features \n",
        "\n",
        "# defining the fully connected layers-- Final Classifier\n",
        "\n",
        "model._fc = nn.Sequential(nn.Linear(num_ftrs, 1280),nn.Linear(1280, out_ftrs),nn.LogSoftmax(dim=1)) \n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.NLLLoss() # negative log likelyhood loss function, useful for class. problems\n",
        "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.01, weight_decay = 0.01)  # Adam optimizer stochastic gradient descent\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) # adaptive learning rate\n",
        "model.to(device);\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model to re-use it\n",
        "\n",
        "model_save_name = \"classifier.pt\"\n",
        "path = F\"/content/drive/My Drive/VP/{model_save_name}\""
      ],
      "metadata": {
        "id": "QWOfJLCnQvd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to unfreeze more layers --- Fine-tuning\n",
        "\n",
        "for name,child in model.named_children():\n",
        "  if name in ['_fc','_swish']:\n",
        "    print(name + 'is unfrozen')\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = True\n",
        "  else:\n",
        "    print(name + 'is frozen')\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.01, weight_decay = 0.01)  # Adam optimizer stochastic gradient descent\n",
        "lambda1 = lambda epoch: 0.65 ** epoch\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)"
      ],
      "metadata": {
        "id": "yOEHRABcQp57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC9re3PY14wO"
      },
      "outputs": [],
      "source": [
        "# outputting the whole model\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the model"
      ],
      "metadata": {
        "id": "fryXh6dufNUy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyM3duF311lj"
      },
      "outputs": [],
      "source": [
        "# to resume the model training later\n",
        "\n",
        "def load_model(path):\n",
        "  checkpoint = torch.load(path)\n",
        "  model.load_state_dict(checkpoint['model_state_dict']) #checkpoint loading the saved state of the model\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict']) #checkpoint loading the saved state of the optimizer\n",
        "  return model\n",
        "model = load_model(\"/content/drive/My Drive/VP/classifier.pt\") # loading the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlCQK8y14FKt"
      },
      "source": [
        "## Training on Training and Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T52JrEMKVT_-"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10   #number of epochs\n",
        "train_loss , validation_loss, acc, f1_s_array = [] , [], [], [] \n",
        "valid_loss_min = np.Inf \n",
        "t1 = time.perf_counter() # to quantify training time\n",
        "\n",
        "\n",
        "model.train()\n",
        "print(\"Model Training started.....\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  current_loss = 0\n",
        "  batch = 0\n",
        "  f1_s_list =  []  # to compute f1-score\n",
        "\n",
        "  for images,labels in train_loader:\n",
        "    images,labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images) #forward\n",
        "    f1_s = f1_score(np.array(labels.to('cpu')),np.array(torch.argmax(outputs, dim = 1).to('cpu')), labels = list(range(5)),average = 'macro', zero_division = 0) #f1 score macro considers each class equally, micro is weighted according to the weight\n",
        "    print(f1_s)\n",
        "    f1_s_list.append(f1_s)\n",
        "    loss = criterion(outputs,labels)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward() #backward\n",
        "    optimizer.step()\n",
        "\n",
        "    current_loss += loss.item()\n",
        "    batch += 1\n",
        "\n",
        "    if batch % 10 == 0:  \n",
        "     print(f\" epoch {epoch + 1} batch {batch} completed\") \n",
        "\n",
        "  valid_l = 0\n",
        "  accuracy = 0\n",
        "  F1_Score = 0\n",
        "\n",
        "  print('Training f1-score is {:.10f}:'.format(sum(f1_s_list)/len(f1_s_list)))\n",
        "\n",
        "  # evaluation on validation set\n",
        "  with torch.no_grad():\n",
        "      f1_s_valid = []\n",
        "      print(f\"validation started for {epoch + 1}\")\n",
        "      model.eval() \n",
        "\n",
        "      for images,labels in valid_loader:\n",
        "          images,labels = images.to(device), labels.to(device)\n",
        "\n",
        "          log_output_val = model(images)\n",
        "          f1_s = f1_score(np.array(labels.to('cpu')),np.array(torch.argmax(log_output_val, dim = 1).to('cpu')), labels = list(range(5)),average = 'macro', zero_division = 0) #f1 score macro cosndiers each class equally, micro is weighted according to the weight\n",
        "          print(f1_s)\n",
        "          f1_s_valid.append(f1_s) \n",
        "          valid_l += criterion(log_output_val,labels) #validation loss\n",
        "          output_val = torch.exp(log_output_val)\n",
        "          top_output , top_output_class = output_val.topk(1,dim=1)\n",
        "          n_corrects = (top_output_class == labels.view(*top_output_class.shape))\n",
        "\n",
        "          accuracy += torch.mean(n_corrects.type(torch.FloatTensor))\n",
        "\n",
        "  print('Validation f1-score is {:.10f}:'.format(sum(f1_s_valid)/len(f1_s_valid)))\n",
        "\n",
        "  # to plot f1 and accuracy values wrt the number of epochs\n",
        "  x = sum(f1_s_valid)/len(f1_s_valid)\n",
        "  f1_s_array.append(x) \n",
        "  train_loss.append(current_loss/len(train_loader))\n",
        "  validation_loss.append(valid_l/len(valid_loader))\n",
        "  acc.append(accuracy//len(valid_loader))\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  print(\"Epoch: {}/{}.. \".format(epoch+1, num_epochs),\"Training Loss: {:.3f}.. \".format(current_loss/len(train_loader)),\"Valid Loss: {:.3f}.. \".format(valid_l/len(valid_loader)),\n",
        "        \"Valid Accuracy: {:.3f}\".format(accuracy/len(valid_loader)))\n",
        "  \n",
        " #the training loop will restart\n",
        "  model.train() \n",
        "\n",
        " # if we have an improvement we save the parameters of the model\n",
        "\n",
        "  if valid_l/len(valid_loader) <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_l/len(valid_loader))) \n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model': model,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': valid_loss_min\n",
        "            }, path)\n",
        "        valid_loss_min = valid_l/len(valid_loader)  \n",
        "  # priniting time needed to train and evaluate       \n",
        "  t2 = time.perf_counter()\n",
        "  print('time taken to run:',t2-t1)\n",
        "  #completed training\n",
        "  print('Training Completed Succesfully !')    \n",
        "\n",
        "# Save the model as a pickle in a file\n",
        "joblib.dump(model, '/content/drive/MyDrive/VP/model.pkl') #useful for future retraining\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgzzwMBmNZDM"
      },
      "source": [
        "### Plotting accuracy and f1-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRUA0eUCeex1"
      },
      "outputs": [],
      "source": [
        "# wrt the number of training epochs\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "plt.xlim([1, 10])\n",
        "plt.ylim([0, 1])\n",
        "plt.plot(acc, label='accuracy')\n",
        "plt.plot(f1_s_array, label='f1-score')\n",
        "plt.legend(\"\")\n",
        "plt.xlabel(\"Epochs\") #x: number of epochs\n",
        "plt.legend(frameon=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwEDdmyB4rnh"
      },
      "source": [
        "## Training on Training and Validation sets + Test scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIfy4oCNBQvK"
      },
      "outputs": [],
      "source": [
        "# unifying training and validation sets\n",
        "\n",
        "train_idx = indices[split1:]\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, sampler = train_sampler, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j6STt8h4uwt"
      },
      "outputs": [],
      "source": [
        "# retraining on the new training set and evaluating on test set\n",
        "num_epochs = 9\n",
        "train_loss , test_loss, acc = [] , [], []\n",
        "test_loss_min = np.Inf \n",
        "t1 = time.perf_counter()\n",
        "f1_array = []\n",
        "\n",
        "\n",
        "# Load the model from the file\n",
        "#model = joblib.load('/content/drive/MyDrive/VP/model.pkl') \n",
        "  \n",
        "model.train()\n",
        "print(\"Model Training started.....\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  current_loss = 0\n",
        "  batch = 0\n",
        "  f1_s_list =  []\n",
        "\n",
        "  for images,labels in train_loader:\n",
        "    images,labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images) #forward\n",
        "\n",
        "    f1_s = f1_score(np.array(labels.to('cpu')),np.array(torch.argmax(outputs, dim = 1).to('cpu')), labels = list(range(5)),average = 'macro', zero_division = 0) #f1 score macro cosndiers each class equally, micro is weighted according to the weight\n",
        "    f1_s_list.append(f1_s)\n",
        "    loss = criterion(outputs,labels)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward() #backward\n",
        "    optimizer.step()\n",
        "\n",
        "    current_loss += loss.item()\n",
        "    batch += 1\n",
        "\n",
        "    if batch % 10 == 0:\n",
        "     print(f\" epoch {epoch + 1} batch {batch} completed\") \n",
        "\n",
        "  test_l = 0\n",
        "  accuracy = 0\n",
        "  F1_Score = 0\n",
        "\n",
        "  print('Training f1-score is {:.10f}:'.format(sum(f1_s_list)/len(f1_s_list)))\n",
        "\n",
        "# evaluating on test set\n",
        "  with torch.no_grad():\n",
        "      f1_s_test = []\n",
        "      print(f\"test started for {epoch + 1}\")\n",
        "      model.eval() \n",
        "\n",
        "      for images,labels in test_loader:\n",
        "          images,labels = images.to(device), labels.to(device)\n",
        "\n",
        "          log_output_val = model(images)\n",
        "          f1_s = f1_score(np.array(labels.to('cpu')),np.array(torch.argmax(log_output_val, dim = 1).to('cpu')), labels = list(range(5)),average = 'macro', zero_division = 0) #f1 score macro cosndiers each class equally, micro is weighted according to the weight\n",
        "          print(f1_s)\n",
        "          f1_s_test.append(f1_s) \n",
        "          test_l += criterion(log_output_val,labels) \n",
        "          output_val = torch.exp(log_output_val)\n",
        "          top_output , top_output_class = output_val.topk(1,dim=1)\n",
        "          n_corrects = (top_output_class == labels.view(*top_output_class.shape))\n",
        "\n",
        "          accuracy += torch.mean(n_corrects.type(torch.FloatTensor))\n",
        "\n",
        "  print('Test f1-score is {:.10f}:'.format(sum(f1_s_test)/len(f1_s_test)))\n",
        "\n",
        "  # to plot the scores\n",
        "  f1_array.append(sum(f1_s_test)/len(f1_s_test))\n",
        "  test_loss.append(test_l/len(valid_loader))\n",
        "  acc.append(accuracy/len(test_loader))\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  print(\"Epoch: {}/{}.. \".format(epoch+1, num_epochs),\"Training Loss: {:.3f}.. \".format(current_loss/len(train_loader)),\"Test Loss: {:.3f}.. \".format(test_l/len(test_loader)),\n",
        "        \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))\n",
        "      \n",
        "  model.train() \n",
        "\n",
        "  # if we have an improvement we save the parameters of the model\n",
        "  \n",
        "  if test_l/len(test_loader) <= test_loss_min:\n",
        "        print('Test loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(test_loss_min,test_l/len(test_loader))) \n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model': model,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': test_loss_min\n",
        "            }, path)\n",
        "        test_loss_min = test_l/len(test_loader)   \n",
        "  # to print time       \n",
        "  t2 = time.perf_counter()\n",
        "  print('time taken to run:',t2-t1)\n",
        "  #completed training and evaluation\n",
        "  print('Training Completed Succesfully !')   \n",
        "\n",
        "# Save the model as a pickle in a file\n",
        "joblib.dump(model, '/content/drive/MyDrive/VP/model.pkl') \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Εvaluation on Test set"
      ],
      "metadata": {
        "id": "y61DClPeR63h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we just evaluate our model on test set, NO TRAINING\n",
        "\n",
        "num_epochs = 10\n",
        "train_loss , test_loss, acc = [] , [], []\n",
        "test_loss_min = np.Inf \n",
        "f1_array = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  current_loss = 0\n",
        "  batch = 0\n",
        "  f1_s_list =  []\n",
        "  test_l = 0\n",
        "  accuracy = 0\n",
        "  F1_Score = 0\n",
        "  with torch.no_grad():\n",
        "      f1_s_test = []\n",
        "      print(f\"test started for {epoch + 1}\")\n",
        "      model.eval() \n",
        "\n",
        "      for images,labels in test_loader:\n",
        "          images,labels = images.to(device), labels.to(device)\n",
        "\n",
        "          log_output_val = model(images)\n",
        "          f1_s = f1_score(np.array(labels.to('cpu')),np.array(torch.argmax(log_output_val, dim = 1).to('cpu')), labels = list(range(5)),average = 'macro', zero_division = 0) #f1 score macro cosndiers each class equally, micro is weighted according to the weight\n",
        "          f1_s_test.append(f1_s) \n",
        "          test_l += criterion(log_output_val,labels) \n",
        "          output_val = torch.exp(log_output_val)\n",
        "          top_output , top_output_class = output_val.topk(1,dim=1)\n",
        "          n_corrects = (top_output_class == labels.view(*top_output_class.shape))\n",
        "\n",
        "          accuracy += torch.mean(n_corrects.type(torch.FloatTensor))\n",
        "          \n",
        "  print('Test f1-score is {:.10f}:'.format(sum(f1_s_test)/len(f1_s_test)))\n",
        "  f1_array.append(sum(f1_s_test)/len(f1_s_test))\n",
        "  test_loss.append(test_l/len(valid_loader))\n",
        "  acc.append(accuracy/len(test_loader))\n",
        "  print(\"Epoch: {}/{}.. \".format(epoch+1, num_epochs),\"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZXtmIlcR5_z",
        "outputId": "40557dbc-a209-41f9-99d6-4c8581907614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test started for 1\n",
            "1.0\n",
            "0.9728997289972898\n",
            "0.9512820512820512\n",
            "1.0\n",
            "1.0\n",
            "0.9268817204301076\n",
            "0.7555555555555555\n",
            "0.9547619047619047\n",
            "0.9535483870967741\n",
            "0.9600989097448579\n",
            "1.0\n",
            "0.7623931623931623\n",
            "Test f1-score is 0.9364517850:\n",
            "Epoch: 1/10..  Test Accuracy: 0.983\n",
            "test started for 2\n",
            "1.0\n",
            "0.974921630094044\n",
            "0.9331070889894418\n",
            "0.9660130718954247\n",
            "0.93289972899729\n",
            "0.8\n",
            "0.7458103803013207\n",
            "0.9883636363636363\n",
            "0.7623792270531401\n",
            "0.7193798449612403\n",
            "0.9649769585253456\n",
            "0.8\n",
            "Test f1-score is 0.8823209639:\n",
            "Epoch: 2/10..  Test Accuracy: 0.975\n",
            "test started for 3\n",
            "0.8740890688259109\n",
            "0.7625396825396825\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "0.9507936507936507\n",
            "1.0\n",
            "0.98110661268556\n",
            "0.9400982093242156\n",
            "0.9223376623376623\n",
            "1.0\n",
            "Test f1-score is 0.9525804072:\n",
            "Epoch: 3/10..  Test Accuracy: 0.983\n",
            "test started for 4\n",
            "0.981338742393509\n",
            "0.9333333333333332\n",
            "1.0\n",
            "0.8\n",
            "0.9405027156751296\n",
            "0.8857142857142858\n",
            "0.8799999999999999\n",
            "1.0\n",
            "0.9504761904761905\n",
            "0.9876679841897232\n",
            "0.9703703703703704\n",
            "0.9418181818181818\n",
            "Test f1-score is 0.9392684837:\n",
            "Epoch: 4/10..  Test Accuracy: 0.980\n",
            "test started for 5\n",
            "0.9723723723723724\n",
            "1.0\n",
            "0.9697777777777778\n",
            "1.0\n",
            "1.0\n",
            "0.9788331071913161\n",
            "1.0\n",
            "0.9813366960907945\n",
            "0.7808278867102396\n",
            "1.0\n",
            "0.7453658536585366\n",
            "1.0\n",
            "Test f1-score is 0.9523761412:\n",
            "Epoch: 5/10..  Test Accuracy: 0.990\n",
            "test started for 6\n",
            "0.9595959595959596\n",
            "0.986031746031746\n",
            "0.9112087912087912\n",
            "0.9554477469541602\n",
            "0.9546688605512135\n",
            "0.9534340056079186\n",
            "0.9094736842105263\n",
            "0.8946153846153846\n",
            "0.9750915750915752\n",
            "0.9640211640211639\n",
            "1.0\n",
            "0.8\n",
            "Test f1-score is 0.9386324098:\n",
            "Epoch: 6/10..  Test Accuracy: 0.979\n",
            "test started for 7\n",
            "0.9057233178577568\n",
            "0.9653679653679653\n",
            "0.9301587301587301\n",
            "1.0\n",
            "0.9237362637362638\n",
            "1.0\n",
            "1.0\n",
            "0.9712918660287082\n",
            "1.0\n",
            "0.9334277017859106\n",
            "0.8984417892761923\n",
            "0.8\n",
            "Test f1-score is 0.9440123029:\n",
            "Epoch: 7/10..  Test Accuracy: 0.980\n",
            "test started for 8\n",
            "1.0\n",
            "0.9522150537634408\n",
            "0.9566666666666667\n",
            "0.966023166023166\n",
            "0.94400784104072\n",
            "0.9303296703296702\n",
            "0.9293237660360948\n",
            "0.911349765258216\n",
            "1.0\n",
            "0.9007467532467534\n",
            "0.9595959595959596\n",
            "1.0\n",
            "Test f1-score is 0.9541882202:\n",
            "Epoch: 8/10..  Test Accuracy: 0.977\n",
            "test started for 9\n",
            "0.9146719946719948\n",
            "0.9196638655462184\n",
            "0.7923809523809524\n",
            "0.7554761904761904\n",
            "0.9523809523809523\n",
            "1.0\n",
            "0.9720634920634922\n",
            "0.9428571428571428\n",
            "0.9766899766899767\n",
            "0.9506332099273276\n",
            "0.7837593984962405\n",
            "1.0\n",
            "Test f1-score is 0.9133814313:\n",
            "Epoch: 9/10..  Test Accuracy: 0.978\n",
            "test started for 10\n",
            "0.9718954248366014\n",
            "0.9330900845186558\n",
            "0.9854183927091963\n",
            "0.9468599033816426\n",
            "0.9717171717171718\n",
            "1.0\n",
            "0.974921630094044\n",
            "0.7818181818181819\n",
            "0.9825210084033614\n",
            "1.0\n",
            "1.0\n",
            "0.5494736842105263\n",
            "Test f1-score is 0.9248096235:\n",
            "Epoch: 10/10..  Test Accuracy: 0.978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting accuracy and F1-Score on Test set"
      ],
      "metadata": {
        "id": "Bn2TfYXjU_G_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "Ia10BC8k9emy",
        "outputId": "0e20cf29-e6e8-4556-fb29-b568c8443f16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f52b02e8e50>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 392,
              "height": 265
            },
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "plt.plot(f1_array, label='Test F1')\n",
        "plt.plot(acc, label='accuracy')\n",
        "plt.xlim([1, 10])\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(\"\")\n",
        "plt.xlabel(\"Epochs\") #x: number of epochs\n",
        "plt.legend(frameon=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "p78922aP1e_7",
        "vZLhWfQQ2mHI",
        "Vbs9kAFa2tOS"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}